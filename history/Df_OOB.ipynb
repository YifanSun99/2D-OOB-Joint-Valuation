{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b7a64cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "------------------------------\n",
      "{'n_data_to_be_valued': 5000, 'n_val': 500, 'n_test': 3000, 'n_trees': 800, 'masked_ratio': 0.5, 'is_noisy': 0.1, 'model_family': 'Tree', 'input_dim': 25, 'run_id': 0, 'rho': 0}\n",
      "--------------------------------------------------\n",
      "GAUSSIAN-C\n",
      "--------------------------------------------------\n",
      "Train X: (5000, 25)\n",
      "Val X: (500, 25)\n",
      "Test X: (3000, 25)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "import datasets\n",
    "from ensemble_DV_core import RandomForestClassifierDV, RandomForestRegressorDV\n",
    "from ensemble_DV_core_original import RandomForestClassifierDV_original, RandomForestRegressorDV_original\n",
    "from data_valuation import DataValuation\n",
    "import utils_eval\n",
    "from utils import *\n",
    "import configs\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import sage\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from scipy.stats import rankdata, ttest_ind\n",
    "\n",
    "import configs\n",
    "config = configs.config000CR()[1][0]\n",
    "problem = config['problem']\n",
    "dataset = config['dataset']\n",
    "dargs_list = config['dargs_list']\n",
    "dargs_ind = 0\n",
    "dargs = dargs_list[dargs_ind]\n",
    "\n",
    "if dataset != 'gaussian':\n",
    "    loo_run=True\n",
    "    betashap_run=True\n",
    "    AME_run=True \n",
    "    lasso_run=True\n",
    "    boosting_run=True\n",
    "    treeshap_run=True\n",
    "    removal_run=True\n",
    "    simple_run=False\n",
    "else:\n",
    "    loo_run=False\n",
    "    betashap_run=False\n",
    "    AME_run=False\n",
    "    lasso_run=False\n",
    "    boosting_run=False\n",
    "    treeshap_run=False\n",
    "    removal_run=False\n",
    "    simple_run=False\n",
    "\n",
    "print(len(dargs_list))\n",
    "(X, y), (X_val, y_val), (X_test, y_test), noisy_index, beta_true = datasets.load_data('clf','gaussian',**dargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be6e259",
   "metadata": {},
   "source": [
    "# loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c0cf2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sim = 10\n",
    "\n",
    "n_dargs_ind_list = []\n",
    "#-6 here since the last 6 settings are too time-consuming\n",
    "for n in range(n_sim):\n",
    "    for dargs_ind in range(len(dargs_list)-6):\n",
    "        n_dargs_ind_list.append((n,dargs_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d05aae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "round:0\n",
      "--------------------------------------------------\n",
      "current dargs: 0 {'n_data_to_be_valued': 5000, 'n_val': 500, 'n_test': 3000, 'n_trees': 800, 'masked_ratio': 0.5, 'is_noisy': 0.1, 'model_family': 'Tree', 'input_dim': 25, 'run_id': 0, 'rho': 0}\n",
      "------------------------------\n",
      "{'n_data_to_be_valued': 5000, 'n_val': 500, 'n_test': 3000, 'n_trees': 800, 'masked_ratio': 0.5, 'is_noisy': 0.1, 'model_family': 'Tree', 'input_dim': 25, 'run_id': 0, 'rho': 0}\n",
      "--------------------------------------------------\n",
      "GAUSSIAN-C\n",
      "--------------------------------------------------\n",
      "Train X: (5000, 25)\n",
      "Val X: (500, 25)\n",
      "Test X: (3000, 25)\n",
      "------------------------------\n",
      "RF 0.782\n",
      "RF_original 0.797\n",
      "gap 0.015\n",
      "Start: Data-OOB computation\n",
      "Done: Data-OOB computation\n",
      "Start: DF-OOB computation\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(n_dargs_ind_list)):\n",
    "    n_dargs_ind = n_dargs_ind_list[idx]\n",
    "    print('*'*50)\n",
    "    n,dargs_ind = n_dargs_ind\n",
    "    print(\"round:%s\"%n)\n",
    "    runpath = r'C:\\Users\\yf-su\\Desktop\\XAI\\run_path_%s'%n\n",
    "    if not os.path.exists(runpath):\n",
    "        os.makedirs(runpath)\n",
    "    print('-'*50)\n",
    "    dargs = dargs_list[dargs_ind]\n",
    "    print(\"current dargs:\",dargs_ind, dargs)\n",
    "    np.random.seed()\n",
    "\n",
    "    # data generation\n",
    "    (X, y), (X_val, y_val), (X_test, y_test), noisy_index, beta_true = datasets.load_data('clf','gaussian',**dargs)\n",
    "\n",
    "    # engine initialization\n",
    "    data_valuation_engine=DataValuation(X=X, y=y, \n",
    "                                            X_val=X_val, y_val=y_val, \n",
    "                                            problem=problem, dargs=dargs)\n",
    "\n",
    "    # rf evaluation, data_shap, feature_shap\n",
    "    data_valuation_engine.evalute_rf_models(X_test, y_test)\n",
    "    data_valuation_engine.compute_data_shap(loo_run=loo_run, \n",
    "                                                    betashap_run=betashap_run)\n",
    "    data_valuation_engine.compute_feature_shap(AME_run=AME_run,\n",
    "                                               lasso_run=lasso_run, \n",
    "                                               boosting_run=boosting_run,\n",
    "                                               treeshap_run=treeshap_run,\n",
    "                                               simple_run=simple_run)\n",
    "\n",
    "    # learn oob\n",
    "    X_y = np.concatenate((X,y.reshape(-1,1)), axis=1)\n",
    "    oob = data_valuation_engine.data_value_dict['Data-OOB']\n",
    "\n",
    "    learn = learn_oob(X_y, oob, global_method = 'SHAP')\n",
    "    base_learn = base_learn_oob(learn['X_y_split'], global_method = 'SHAP')\n",
    "\n",
    "    # store values\n",
    "    data_valuation_engine.feature_value_dict['Learn-OOB'] = learn['learn_feature_importance']\n",
    "    data_valuation_engine.learn_dict['Learn-OOB-y'] = learn['learn_feature_importance_y']    \n",
    "    data_valuation_engine.feature_value_dict['Base-Learn-OOB'] = base_learn['learn_feature_importance']\n",
    "\n",
    "    data_valuation_engine.learn_dict['mape'] = learn['score_mape']\n",
    "    data_valuation_engine.learn_dict['mse'] = learn['score_mse']\n",
    "    data_valuation_engine.learn_dict['acc(base)'] = base_learn['score_acc']\n",
    "\n",
    "    # attribution difference (1:A<B 2:A>B)\n",
    "    attrA = data_valuation_engine.feature_value_dict['Learn-OOB']\n",
    "    attrB = data_valuation_engine.feature_value_dict['Base-Learn-OOB']\n",
    "    attr_diff = (preprocessing.normalize(attrA.reshape(1,-1)) - preprocessing.normalize(\n",
    "        attrB.reshape(1,-1))).reshape(-1)\n",
    "\n",
    "    rank_true = rankdata(-np.abs(beta_true), method='ordinal')\n",
    "    rank_true[beta_true.reshape(1,-1)[0] == 0] = -1\n",
    "    data_valuation_engine.learn_dict['attr_diff_outlier_1'] = rank_true[detect_outlier(attr_diff)[0]]\n",
    "    data_valuation_engine.learn_dict['attr_diff_outlier_2'] = rank_true[detect_outlier(attr_diff)[1]]\n",
    "    data_valuation_engine.learn_dict['non_masked_feature'] = (beta_true != 0).sum()\n",
    "\n",
    "    rank_true = rankdata(-np.abs(beta_true), method='dense')\n",
    "    data_valuation_engine.learn_dict['attr_diff_top3'] = np.mean(rank_true[np.argsort(attr_diff) <= 2])\n",
    "    data_valuation_engine.learn_dict['attr_diff_bottom3'] = np.mean(rank_true[np.argsort(-attr_diff) <= 2])\n",
    "\n",
    "    data_valuation_engine.learn_dict['pearson'] = rcorr(attrA, attrB)[0]\n",
    "    data_valuation_engine.learn_dict['tau'] = rcorr(attrA, attrB)[1]\n",
    "\n",
    "    data_valuation_engine.evaluate_data_values(noisy_index, beta_true, X_test, y_test, removal_run=removal_run)\n",
    "    data_valuation_engine.new_evaluation_dict = utils_eval.evalution_new(oob, noisy_index, learn['model'], X_y, beta_true, dargs['rho'])\n",
    "    data_valuation_engine.save_results(runpath, dataset, dargs_ind, noisy_index, beta_true)\n",
    "    \n",
    "    # check for replicate\n",
    "    if idx >= (len(dargs_list)-6):\n",
    "        n,dargs_ind = n_dargs_ind_list[idx - (len(dargs_list)-6)]\n",
    "        past = np.load(r\"C:\\Users\\yf-su\\Desktop\\XAI\\run_path_%d\\run_id0_%d.pkl\"%(n,dargs_ind), allow_pickle = True)\n",
    "        if (data_valuation_engine.feature_value_dict['Learn-OOB'] == past['feature_value']['Learn-OOB']).all():\n",
    "            raise\n",
    "    del X, y, X_val, y_val, X_test, y_test, X_y, oob\n",
    "    del data_valuation_engine, learn, base_learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f12549c",
   "metadata": {},
   "source": [
    "# Important analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d3e6c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_balance(X_y):\n",
    "    count = np.bincount(X_y[:,-1].astype(int))\n",
    "    return max(count)/sum(count)\n",
    "def generate_X_y_oob(dargs):\n",
    "    np.random.seed()\n",
    "    # data generation\n",
    "    (X, y), (X_val, y_val), (X_test, y_test), noisy_index, beta_true = datasets.load_data('clf','gaussian',**dargs)\n",
    "\n",
    "    # engine initialization\n",
    "    data_valuation_engine=DataValuation(X=X, y=y, \n",
    "                                            X_val=X_val, y_val=y_val, \n",
    "                                            problem=problem, dargs=dargs)\n",
    "\n",
    "    # rf evaluation, data_shap, feature_shap\n",
    "    data_valuation_engine.evalute_rf_models(X_test, y_test)\n",
    "    data_valuation_engine.compute_data_shap(loo_run=loo_run, \n",
    "                                                    betashap_run=betashap_run)\n",
    "    data_valuation_engine.compute_feature_shap(AME_run=AME_run,\n",
    "                                               lasso_run=lasso_run, \n",
    "                                               boosting_run=boosting_run,\n",
    "                                               treeshap_run=treeshap_run,\n",
    "                                               simple_run=simple_run,\n",
    "                                               df_oob_run=False)\n",
    "\n",
    "    # learn oob\n",
    "    X_y = np.concatenate((X,y.reshape(-1,1)), axis=1)\n",
    "    oob = data_valuation_engine.data_value_dict['Data-OOB']\n",
    "    return X_y, oob\n",
    "\n",
    "def f(f):\n",
    "    return str(round(f,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c96e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "{'n_data_to_be_valued': 5000, 'n_val': 500, 'n_test': 3000, 'n_trees': 800, 'masked_ratio': 0.5, 'is_noisy': 0.1, 'model_family': 'Tree', 'input_dim': 25, 'run_id': 0, 'rho': 0}\n",
      "--------------------------------------------------\n",
      "GAUSSIAN-C\n",
      "--------------------------------------------------\n",
      "Train X: (5000, 25)\n",
      "Val X: (500, 25)\n",
      "Test X: (3000, 25)\n",
      "------------------------------\n",
      "RF 0.772\n",
      "RF_original 0.779\n",
      "gap 0.007\n",
      "Start: Data-OOB computation\n",
      "Done: Data-OOB computation\n"
     ]
    }
   ],
   "source": [
    "dargs_ind = 0\n",
    "dargs = dargs_list[dargs_ind]\n",
    "X_y, oob = generate_X_y_oob(dargs)\n",
    "learn = learn_oob(X_y, oob, global_method = 'SHAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93240bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dargs_ind in range(18):\n",
    "\n",
    "    runpath = r'C:\\Users\\yf-su\\Desktop\\XAI\\Y\\experiment_%s\\\\'%dargs_ind \n",
    "    if not os.path.exists(runpath):\n",
    "        os.makedirs(runpath)\n",
    "\n",
    "    dargs = dargs_list[dargs_ind]\n",
    "    X_y, oob = generate_X_y_oob(dargs)\n",
    "    learn = learn_oob(X_y, oob, global_method = 'SHAP')\n",
    "\n",
    "    end_point = 25 if dargs['n_data_to_be_valued'] == 5000 else 10\n",
    "\n",
    "    with open(runpath+'log.txt','w') as file:\n",
    "        file.writelines(['quantile','\\t','value','\\t','t','\\t','p'])\n",
    "        for top in range(9,0,-1):\n",
    "            top = top/10\n",
    "            file.writelines(\"\\n\")\n",
    "            top_ind_test = np.where(learn['oob_split'][2]>=np.quantile(oob,1-top))\n",
    "            bottom_ind_test = np.where(learn['oob_split'][2]<np.quantile(oob,1-top))\n",
    "            t_test = ttest_ind(learn['local_importance'][:,-1][top_ind_test],learn['local_importance'][:,-1][bottom_ind_test])\n",
    "            file.writelines([str(top),'\\t',f(np.quantile(oob,1-top)),'\\t'])\n",
    "            file.writelines([f(t_test[0]),'\\t',f(t_test[1])])\n",
    "            file.writelines(\"\\n\")\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(learn['oob_split'][2],learn['local_importance'][:,-1])\n",
    "    plt.xlabel(\"OOB\")\n",
    "    plt.ylabel(\"y_importance\")\n",
    "    plt.savefig(runpath+\"scatter_plot.jpg\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    results_order = []\n",
    "    results_balance = []\n",
    "    results_mape = []\n",
    "\n",
    "    tops = []\n",
    "    for top in tqdm.tqdm(range(100,end_point,-5)):\n",
    "        top = top/100\n",
    "        tops.append(top)\n",
    "\n",
    "        top_ind = np.where(oob>=np.quantile(oob,1-top))\n",
    "        X_y_sub = X_y[top_ind]\n",
    "        oob_sub = oob[top_ind]\n",
    "\n",
    "        learn = learn_oob(X_y_sub, oob_sub, global_method = 'SHAP')\n",
    "\n",
    "        results_order.append(learn['learn_feature_importance_y_order'])\n",
    "        results_balance.append(count_balance(X_y_sub))\n",
    "        results_mape.append(learn['score_mape'])\n",
    "\n",
    "    plt.plot(tops,results_order,label = 'y_order')\n",
    "    plt.plot(tops,results_balance,label = 'balance')\n",
    "    plt.xlabel(\"keep_percentage\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.savefig(runpath+\"trend_1.jpg\")\n",
    "    plt.show()\n",
    "    plt.plot(tops,np.array(results_mape)/100, label = 'mse')\n",
    "    plt.xlabel(\"keep_percentage\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.savefig(runpath+\"trend_2.jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2e74e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0e0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e103deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
